{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "7f74e76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import plot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "dataFrame = pd.read_csv('sonar_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3ea57c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6aa34b5",
   "metadata": {},
   "source": [
    "دیتا نال نداریم در نتیجه نیازی به حذف کردن هم نداریم "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "34f7e21f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attribute_1</th>\n",
       "      <th>attribute_2</th>\n",
       "      <th>attribute_3</th>\n",
       "      <th>attribute_4</th>\n",
       "      <th>attribute_5</th>\n",
       "      <th>attribute_6</th>\n",
       "      <th>attribute_7</th>\n",
       "      <th>attribute_8</th>\n",
       "      <th>attribute_9</th>\n",
       "      <th>attribute_10</th>\n",
       "      <th>...</th>\n",
       "      <th>attribute_52</th>\n",
       "      <th>attribute_53</th>\n",
       "      <th>attribute_54</th>\n",
       "      <th>attribute_55</th>\n",
       "      <th>attribute_56</th>\n",
       "      <th>attribute_57</th>\n",
       "      <th>attribute_58</th>\n",
       "      <th>attribute_59</th>\n",
       "      <th>attribute_60</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   attribute_1  attribute_2  attribute_3  attribute_4  attribute_5  \\\n",
       "0       0.0200       0.0371       0.0428       0.0207       0.0954   \n",
       "1       0.0453       0.0523       0.0843       0.0689       0.1183   \n",
       "2       0.0262       0.0582       0.1099       0.1083       0.0974   \n",
       "3       0.0100       0.0171       0.0623       0.0205       0.0205   \n",
       "4       0.0762       0.0666       0.0481       0.0394       0.0590   \n",
       "\n",
       "   attribute_6  attribute_7  attribute_8  attribute_9  attribute_10  ...  \\\n",
       "0       0.0986       0.1539       0.1601       0.3109        0.2111  ...   \n",
       "1       0.2583       0.2156       0.3481       0.3337        0.2872  ...   \n",
       "2       0.2280       0.2431       0.3771       0.5598        0.6194  ...   \n",
       "3       0.0368       0.1098       0.1276       0.0598        0.1264  ...   \n",
       "4       0.0649       0.1209       0.2467       0.3564        0.4459  ...   \n",
       "\n",
       "   attribute_52  attribute_53  attribute_54  attribute_55  attribute_56  \\\n",
       "0        0.0027        0.0065        0.0159        0.0072        0.0167   \n",
       "1        0.0084        0.0089        0.0048        0.0094        0.0191   \n",
       "2        0.0232        0.0166        0.0095        0.0180        0.0244   \n",
       "3        0.0121        0.0036        0.0150        0.0085        0.0073   \n",
       "4        0.0031        0.0054        0.0105        0.0110        0.0015   \n",
       "\n",
       "   attribute_57  attribute_58  attribute_59  attribute_60  Class  \n",
       "0        0.0180        0.0084        0.0090        0.0032   Rock  \n",
       "1        0.0140        0.0049        0.0052        0.0044   Rock  \n",
       "2        0.0316        0.0164        0.0095        0.0078   Rock  \n",
       "3        0.0050        0.0044        0.0040        0.0117   Rock  \n",
       "4        0.0072        0.0048        0.0107        0.0094   Rock  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ef4c80",
   "metadata": {},
   "source": [
    "دیتا را با استفاده از کم کردن از میانگین و تقسیم کردن بر واریانس نرمال میکنیم "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "4783fa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame_normal = (  dataFrame.iloc[:,:60] - dataFrame.iloc[:,:60].mean()  ) / dataFrame.iloc[:,:60].var()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebf3328",
   "metadata": {},
   "source": [
    "دیتا را به صورت رندوم و با نسبت 80 به 20 تقسیم میکنیم "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3bce3b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8636363636363636"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inds = np.random.choice(range(208), (208 // 5)*4 , replace=False)\n",
    "mylist = []\n",
    "for i in range(0,208):\n",
    "    if i not in inds:\n",
    "        mylist.append(i)  \n",
    "        \n",
    "X_train = dataFrame_normal.values[inds]\n",
    "X_test = dataFrame_normal.values[mylist]\n",
    "Y_train = dataFrame['Class'].values[inds]\n",
    "Y_test = dataFrame['Class'].values[mylist]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11347f86",
   "metadata": {},
   "source": [
    "## Linear "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "f771adcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_linear = SVC(kernel='linear',C=0.5,class_weight='balanced')\n",
    "clf_linear.fit(X_train, Y_train)\n",
    "y_predict_test_linear = clf_linear.predict(X_test)\n",
    "y_predict_train_linear = clf_linear.predict(X_train)\n",
    "accuracy_test_linear = round( accuracy_score(Y_test , y_predict_test_linear) , 2 )\n",
    "accuracy_train_linear = round(  accuracy_score(Y_train , y_predict_train_linear) , 2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bffe5f",
   "metadata": {},
   "source": [
    "## ploynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "29c424c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_poly = SVC(kernel='poly',C = 250,degree=2,coef0=25)\n",
    "clf_poly.fit(X_train, Y_train)\n",
    "y_predict_test_polynomial = clf_poly.predict(X_test)\n",
    "y_predict_train_polynomial = clf_poly.predict(X_train)\n",
    "accuracy_test_poly = round( accuracy_score(Y_test , y_predict_test_polynomial) , 2 )\n",
    "accuracy_train_poly = round( accuracy_score(Y_train , y_predict_train_polynomial) , 2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afd50fd",
   "metadata": {},
   "source": [
    "## RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "a31d13a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rbf = SVC(kernel='rbf',C=40)\n",
    "clf_rbf.fit(X_train, Y_train)\n",
    "y_predict_test_rbf = clf_rbf.predict(X_test)\n",
    "y_predict_train_rbf = clf_rbf.predict(X_train)\n",
    "accuracy_test_rbf = round( accuracy_score(Y_test , y_predict_test_rbf) , 2 )\n",
    "accuracy_train_rbf = round ( accuracy_score(Y_train , y_predict_train_rbf) , 2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "bafe1f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train linear 0.99\n",
      "accuracy test linear 0.86\n",
      "accuracy train polynomial 1.0\n",
      "accuracy test polynomial 0.91\n",
      "accuracy train RBF  0.99\n",
      "accuracy test RBF  0.77\n"
     ]
    }
   ],
   "source": [
    "print('accuracy train linear' , accuracy_train_linear ) \n",
    "print('accuracy test linear' , accuracy_test_linear )\n",
    "print('accuracy train polynomial' , accuracy_train_poly )\n",
    "print('accuracy test polynomial' , accuracy_test_poly )\n",
    "print('accuracy train RBF ' , accuracy_train_rbf )\n",
    "print('accuracy test RBF ' , accuracy_test_rbf )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a88598",
   "metadata": {},
   "source": [
    "| SVM kernel  | Kernel parameter Value | Accuracy on Train | Accuracy on Test |\n",
    "| --- | --- | --- | --- |\n",
    "| Linear | C=0.5 | 0.99 | 0.86 | \n",
    "| polynomial | C=250 , degree=2 , coef0=25 | 1 | 0.91 |\n",
    "| RBF | C=40 | 0.99 | 0.77 | "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
